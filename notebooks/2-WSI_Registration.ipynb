{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Towards Cellular-Level Alignment: A Coarse-to-Fine Approach for Multistain Whole Slide Image Registration\n",
    "\n",
    "This notebook demonstrates the complete workflow for Whole Slide Image (WSI) registration using rigid and non-rigid techniques with nuclei-based analysis.\n",
    "\n",
    "## Overview\n",
    "- **Coarse Registration**: Initial coarse alignment using traditional techniques\n",
    "- **Fine Shape-aware Nuclei based Registration**: Point cloud-based fine alignment and coherent Point Drift (CPD) for local deformation\n",
    "- **Interactive Visualization**: Bokeh plots for analysis\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "# Add project root to PYTHONPATH\n",
    "project_root = os.path.abspath(os.path.join(os.getcwd(), \"..\"))  # adjust if needed\n",
    "if project_root not in sys.path:\n",
    "    sys.path.insert(0, project_root)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jupyter environment detected. Enabling Open3D WebVisualizer.\n",
      "[Open3D INFO] WebRTC GUI backend enabled.\n",
      "[Open3D INFO] WebRTCWindowSystem: HTTP handshake server disabled.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "|2025-10-27|23:29:52.131| [WARNING] /home/u5552013/miniconda3/envs/tiatoolbox-reg-vis/lib/python3.9/site-packages/albumentations/__init__.py:24: UserWarning: A new version of Albumentations is available: 2.0.8 (you have 1.4.21). Upgrade using: pip install -U albumentations. To disable automatic update checks, set the environment variable NO_ALBUMENTATIONS_UPDATE to 1.\n",
      "  check_for_updates()\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "    <style>\n",
       "        .bk-notebook-logo {\n",
       "            display: block;\n",
       "            width: 20px;\n",
       "            height: 20px;\n",
       "            background-image: url(data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAUCAYAAACNiR0NAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAABx0RVh0U29mdHdhcmUAQWRvYmUgRmlyZXdvcmtzIENTNui8sowAAAOkSURBVDiNjZRtaJVlGMd/1/08zzln5zjP1LWcU9N0NkN8m2CYjpgQYQXqSs0I84OLIC0hkEKoPtiH3gmKoiJDU7QpLgoLjLIQCpEsNJ1vqUOdO7ppbuec5+V+rj4ctwzd8IIbbi6u+8f1539dt3A78eXC7QizUF7gyV1fD1Yqg4JWz84yffhm0qkFqBogB9rM8tZdtwVsPUhWhGcFJngGeWrPzHm5oaMmkfEg1usvLFyc8jLRqDOMru7AyC8saQr7GG7f5fvDeH7Ej8CM66nIF+8yngt6HWaKh7k49Soy9nXurCi1o3qUbS3zWfrYeQDTB/Qj6kX6Ybhw4B+bOYoLKCC9H3Nu/leUTZ1JdRWkkn2ldcCamzrcf47KKXdAJllSlxAOkRgyHsGC/zRday5Qld9DyoM4/q/rUoy/CXh3jzOu3bHUVZeU+DEn8FInkPBFlu3+nW3Nw0mk6vCDiWg8CeJaxEwuHS3+z5RgY+YBR6V1Z1nxSOfoaPa4LASWxxdNp+VWTk7+4vzaou8v8PN+xo+KY2xsw6une2frhw05CTYOmQvsEhjhWjn0bmXPjpE1+kplmmkP3suftwTubK9Vq22qKmrBhpY4jvd5afdRA3wGjFAgcnTK2s4hY0/GPNIb0nErGMCRxWOOX64Z8RAC4oCXdklmEvcL8o0BfkNK4lUg9HTl+oPlQxdNo3Mg4Nv175e/1LDGzZen30MEjRUtmXSfiTVu1kK8W4txyV6BMKlbgk3lMwYCiusNy9fVfvvwMxv8Ynl6vxoByANLTWplvuj/nF9m2+PDtt1eiHPBr1oIfhCChQMBw6Aw0UulqTKZdfVvfG7VcfIqLG9bcldL/+pdWTLxLUy8Qq38heUIjh4XlzZxzQm19lLFlr8vdQ97rjZVOLf8nclzckbcD4wxXMidpX30sFd37Fv/GtwwhzhxGVAprjbg0gCAEeIgwCZyTV2Z1REEW8O4py0wsjeloKoMr6iCY6dP92H6Vw/oTyICIthibxjm/DfN9lVz8IqtqKYLUXfoKVMVQVVJOElGjrnnUt9T9wbgp8AyYKaGlqingHZU/uG2NTZSVqwHQTWkx9hxjkpWDaCg6Ckj5qebgBVbT3V3NNXMSiWSDdGV3hrtzla7J+duwPOToIg42ChPQOQjspnSlp1V+Gjdged7+8UN5CRAV7a5EdFNwCjEaBR27b3W890TE7g24NAP/mMDXRWrGoFPQI9ls/MWO2dWFAar/xcOIImbbpA3zgAAAABJRU5ErkJggg==);\n",
       "        }\n",
       "    </style>\n",
       "    <div>\n",
       "        <a href=\"https://bokeh.org\" target=\"_blank\" class=\"bk-notebook-logo\"></a>\n",
       "        <span id=\"cf58c545-22c1-4b28-8962-895effd1752e\">Loading BokehJS ...</span>\n",
       "    </div>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": "'use strict';\n(function(root) {\n  function now() {\n    return new Date();\n  }\n\n  const force = true;\n\n  if (typeof root._bokeh_onload_callbacks === \"undefined\" || force === true) {\n    root._bokeh_onload_callbacks = [];\n    root._bokeh_is_loading = undefined;\n  }\n\nconst JS_MIME_TYPE = 'application/javascript';\n  const HTML_MIME_TYPE = 'text/html';\n  const EXEC_MIME_TYPE = 'application/vnd.bokehjs_exec.v0+json';\n  const CLASS_NAME = 'output_bokeh rendered_html';\n\n  /**\n   * Render data to the DOM node\n   */\n  function render(props, node) {\n    const script = document.createElement(\"script\");\n    node.appendChild(script);\n  }\n\n  /**\n   * Handle when an output is cleared or removed\n   */\n  function handleClearOutput(event, handle) {\n    function drop(id) {\n      const view = Bokeh.index.get_by_id(id)\n      if (view != null) {\n        view.model.document.clear()\n        Bokeh.index.delete(view)\n      }\n    }\n\n    const cell = handle.cell;\n\n    const id = cell.output_area._bokeh_element_id;\n    const server_id = cell.output_area._bokeh_server_id;\n\n    // Clean up Bokeh references\n    if (id != null) {\n      drop(id)\n    }\n\n    if (server_id !== undefined) {\n      // Clean up Bokeh references\n      const cmd_clean = \"from bokeh.io.state import curstate; print(curstate().uuid_to_server['\" + server_id + \"'].get_sessions()[0].document.roots[0]._id)\";\n      cell.notebook.kernel.execute(cmd_clean, {\n        iopub: {\n          output: function(msg) {\n            const id = msg.content.text.trim()\n            drop(id)\n          }\n        }\n      });\n      // Destroy server and session\n      const cmd_destroy = \"import bokeh.io.notebook as ion; ion.destroy_server('\" + server_id + \"')\";\n      cell.notebook.kernel.execute(cmd_destroy);\n    }\n  }\n\n  /**\n   * Handle when a new output is added\n   */\n  function handleAddOutput(event, handle) {\n    const output_area = handle.output_area;\n    const output = handle.output;\n\n    // limit handleAddOutput to display_data with EXEC_MIME_TYPE content only\n    if ((output.output_type != \"display_data\") || (!Object.prototype.hasOwnProperty.call(output.data, EXEC_MIME_TYPE))) {\n      return\n    }\n\n    const toinsert = output_area.element.find(\".\" + CLASS_NAME.split(' ')[0]);\n\n    if (output.metadata[EXEC_MIME_TYPE][\"id\"] !== undefined) {\n      toinsert[toinsert.length - 1].firstChild.textContent = output.data[JS_MIME_TYPE];\n      // store reference to embed id on output_area\n      output_area._bokeh_element_id = output.metadata[EXEC_MIME_TYPE][\"id\"];\n    }\n    if (output.metadata[EXEC_MIME_TYPE][\"server_id\"] !== undefined) {\n      const bk_div = document.createElement(\"div\");\n      bk_div.innerHTML = output.data[HTML_MIME_TYPE];\n      const script_attrs = bk_div.children[0].attributes;\n      for (let i = 0; i < script_attrs.length; i++) {\n        toinsert[toinsert.length - 1].firstChild.setAttribute(script_attrs[i].name, script_attrs[i].value);\n        toinsert[toinsert.length - 1].firstChild.textContent = bk_div.children[0].textContent\n      }\n      // store reference to server id on output_area\n      output_area._bokeh_server_id = output.metadata[EXEC_MIME_TYPE][\"server_id\"];\n    }\n  }\n\n  function register_renderer(events, OutputArea) {\n\n    function append_mime(data, metadata, element) {\n      // create a DOM node to render to\n      const toinsert = this.create_output_subarea(\n        metadata,\n        CLASS_NAME,\n        EXEC_MIME_TYPE\n      );\n      this.keyboard_manager.register_events(toinsert);\n      // Render to node\n      const props = {data: data, metadata: metadata[EXEC_MIME_TYPE]};\n      render(props, toinsert[toinsert.length - 1]);\n      element.append(toinsert);\n      return toinsert\n    }\n\n    /* Handle when an output is cleared or removed */\n    events.on('clear_output.CodeCell', handleClearOutput);\n    events.on('delete.Cell', handleClearOutput);\n\n    /* Handle when a new output is added */\n    events.on('output_added.OutputArea', handleAddOutput);\n\n    /**\n     * Register the mime type and append_mime function with output_area\n     */\n    OutputArea.prototype.register_mime_type(EXEC_MIME_TYPE, append_mime, {\n      /* Is output safe? */\n      safe: true,\n      /* Index of renderer in `output_area.display_order` */\n      index: 0\n    });\n  }\n\n  // register the mime type if in Jupyter Notebook environment and previously unregistered\n  if (root.Jupyter !== undefined) {\n    const events = require('base/js/events');\n    const OutputArea = require('notebook/js/outputarea').OutputArea;\n\n    if (OutputArea.prototype.mime_types().indexOf(EXEC_MIME_TYPE) == -1) {\n      register_renderer(events, OutputArea);\n    }\n  }\n  if (typeof (root._bokeh_timeout) === \"undefined\" || force === true) {\n    root._bokeh_timeout = Date.now() + 5000;\n    root._bokeh_failed_load = false;\n  }\n\n  const NB_LOAD_WARNING = {'data': {'text/html':\n     \"<div style='background-color: #fdd'>\\n\"+\n     \"<p>\\n\"+\n     \"BokehJS does not appear to have successfully loaded. If loading BokehJS from CDN, this \\n\"+\n     \"may be due to a slow or bad network connection. Possible fixes:\\n\"+\n     \"</p>\\n\"+\n     \"<ul>\\n\"+\n     \"<li>re-rerun `output_notebook()` to attempt to load from CDN again, or</li>\\n\"+\n     \"<li>use INLINE resources instead, as so:</li>\\n\"+\n     \"</ul>\\n\"+\n     \"<code>\\n\"+\n     \"from bokeh.resources import INLINE\\n\"+\n     \"output_notebook(resources=INLINE)\\n\"+\n     \"</code>\\n\"+\n     \"</div>\"}};\n\n  function display_loaded(error = null) {\n    const el = document.getElementById(\"cf58c545-22c1-4b28-8962-895effd1752e\");\n    if (el != null) {\n      const html = (() => {\n        if (typeof root.Bokeh === \"undefined\") {\n          if (error == null) {\n            return \"BokehJS is loading ...\";\n          } else {\n            return \"BokehJS failed to load.\";\n          }\n        } else {\n          const prefix = `BokehJS ${root.Bokeh.version}`;\n          if (error == null) {\n            return `${prefix} successfully loaded.`;\n          } else {\n            return `${prefix} <b>encountered errors</b> while loading and may not function as expected.`;\n          }\n        }\n      })();\n      el.innerHTML = html;\n\n      if (error != null) {\n        const wrapper = document.createElement(\"div\");\n        wrapper.style.overflow = \"auto\";\n        wrapper.style.height = \"5em\";\n        wrapper.style.resize = \"vertical\";\n        const content = document.createElement(\"div\");\n        content.style.fontFamily = \"monospace\";\n        content.style.whiteSpace = \"pre-wrap\";\n        content.style.backgroundColor = \"rgb(255, 221, 221)\";\n        content.textContent = error.stack ?? error.toString();\n        wrapper.append(content);\n        el.append(wrapper);\n      }\n    } else if (Date.now() < root._bokeh_timeout) {\n      setTimeout(() => display_loaded(error), 100);\n    }\n  }\n\n  function run_callbacks() {\n    try {\n      root._bokeh_onload_callbacks.forEach(function(callback) {\n        if (callback != null)\n          callback();\n      });\n    } finally {\n      delete root._bokeh_onload_callbacks\n    }\n    console.debug(\"Bokeh: all callbacks have finished\");\n  }\n\n  function load_libs(css_urls, js_urls, callback) {\n    if (css_urls == null) css_urls = [];\n    if (js_urls == null) js_urls = [];\n\n    root._bokeh_onload_callbacks.push(callback);\n    if (root._bokeh_is_loading > 0) {\n      console.debug(\"Bokeh: BokehJS is being loaded, scheduling callback at\", now());\n      return null;\n    }\n    if (js_urls == null || js_urls.length === 0) {\n      run_callbacks();\n      return null;\n    }\n    console.debug(\"Bokeh: BokehJS not loaded, scheduling load and callback at\", now());\n    root._bokeh_is_loading = css_urls.length + js_urls.length;\n\n    function on_load() {\n      root._bokeh_is_loading--;\n      if (root._bokeh_is_loading === 0) {\n        console.debug(\"Bokeh: all BokehJS libraries/stylesheets loaded\");\n        run_callbacks()\n      }\n    }\n\n    function on_error(url) {\n      console.error(\"failed to load \" + url);\n    }\n\n    for (let i = 0; i < css_urls.length; i++) {\n      const url = css_urls[i];\n      const element = document.createElement(\"link\");\n      element.onload = on_load;\n      element.onerror = on_error.bind(null, url);\n      element.rel = \"stylesheet\";\n      element.type = \"text/css\";\n      element.href = url;\n      console.debug(\"Bokeh: injecting link tag for BokehJS stylesheet: \", url);\n      document.body.appendChild(element);\n    }\n\n    for (let i = 0; i < js_urls.length; i++) {\n      const url = js_urls[i];\n      const element = document.createElement('script');\n      element.onload = on_load;\n      element.onerror = on_error.bind(null, url);\n      element.async = false;\n      element.src = url;\n      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n      document.head.appendChild(element);\n    }\n  };\n\n  function inject_raw_css(css) {\n    const element = document.createElement(\"style\");\n    element.appendChild(document.createTextNode(css));\n    document.body.appendChild(element);\n  }\n\n  const js_urls = [\"https://cdn.bokeh.org/bokeh/release/bokeh-3.4.3.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-gl-3.4.3.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-widgets-3.4.3.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-tables-3.4.3.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-mathjax-3.4.3.min.js\"];\n  const css_urls = [];\n\n  const inline_js = [    function(Bokeh) {\n      Bokeh.set_log_level(\"info\");\n    },\nfunction(Bokeh) {\n    }\n  ];\n\n  function run_inline_js() {\n    if (root.Bokeh !== undefined || force === true) {\n      try {\n            for (let i = 0; i < inline_js.length; i++) {\n      inline_js[i].call(root, root.Bokeh);\n    }\n\n      } catch (error) {display_loaded(error);throw error;\n      }if (force === true) {\n        display_loaded();\n      }} else if (Date.now() < root._bokeh_timeout) {\n      setTimeout(run_inline_js, 100);\n    } else if (!root._bokeh_failed_load) {\n      console.log(\"Bokeh: BokehJS failed to load within specified timeout.\");\n      root._bokeh_failed_load = true;\n    } else if (force !== true) {\n      const cell = $(document.getElementById(\"cf58c545-22c1-4b28-8962-895effd1752e\")).parents('.cell').data().cell;\n      cell.output_area.append_execute_result(NB_LOAD_WARNING)\n    }\n  }\n\n  if (root._bokeh_is_loading === 0) {\n    console.debug(\"Bokeh: BokehJS loaded, going straight to plotting\");\n    run_inline_js();\n  } else {\n    load_libs(css_urls, js_urls, function() {\n      console.debug(\"Bokeh: BokehJS plotting callback run at\", now());\n      run_inline_js();\n    });\n  }\n}(window));",
      "application/vnd.bokehjs_load.v0+json": ""
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ All modules imported successfully!\n",
      "Source WSI: /home/u5552013/Nextcloud/HYRECO/Data/Image/ki67_533.tif\n",
      "Target WSI: /home/u5552013/Nextcloud/HYRECO/Data/Image/he_533.tif\n"
     ]
    }
   ],
   "source": [
    "\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import SimpleITK as sitk\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from core.utils.imports import *\n",
    "from core.config import *\n",
    "from core.preprocessing.padding import *\n",
    "from core.preprocessing.preprocessing import *\n",
    "from core.registration.registration import *\n",
    "from core.evaluation.evaluation import *\n",
    "from core.visualization.visualization import *\n",
    "from core.preprocessing.nuclei_analysis import *\n",
    "from core.preprocessing.stainnorm import *\n",
    "from core.registration.nonrigid import *\n",
    "from core.cpd import *\n",
    "\n",
    "\n",
    "# Setup Bokeh for notebook output\n",
    "setup_bokeh_notebook()\n",
    "\n",
    "print(\"✅ All modules imported successfully!\")\n",
    "print(f\"Source WSI: {SOURCE_WSI_PATH}\")\n",
    "print(f\"Target WSI: {TARGET_WSI_PATH}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Configuration Check\n",
    "\n",
    "Verify that all file paths are correct and files exist."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Check if files exist\n",
    "files_to_check = [\n",
    "    SOURCE_WSI_PATH,\n",
    "    TARGET_WSI_PATH,\n",
    "    FIXED_POINTS_PATH,\n",
    "    MOVING_POINTS_PATH\n",
    "]\n",
    "\n",
    "print(\"File existence check:\")\n",
    "for file_path in files_to_check:\n",
    "    exists = os.path.exists(file_path)\n",
    "    status = \"✅\" if exists else \"❌\"\n",
    "    print(f\"{status} {file_path}\")\n",
    "\n",
    "# Display current parameters\n",
    "print(\"\\nCurrent Parameters:\")\n",
    "print(f\"- Preprocessing Resolution: {PREPROCESSING_RESOLUTION}\")\n",
    "print(f\"- Registration Resolution: {REGISTRATION_RESOLUTION}\")\n",
    "print(f\"- Patch Size: {PATCH_SIZE}\")\n",
    "print(f\"- Fixed Threshold: {FIXED_THRESHOLD}\")\n",
    "print(f\"- Moving Threshold: {MOVING_THRESHOLD}\")\n",
    "print(f\"- Min Nuclei Area: {MIN_NUCLEI_AREA}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Load and Preprocess WSIs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load WSI images\n",
    "print(\"Loading WSI images...\")\n",
    "source_wsi, target_wsi, source, target = load_wsi_images(\n",
    "    SOURCE_WSI_PATH, TARGET_WSI_PATH, PREPROCESSING_RESOLUTION\n",
    ")\n",
    "\n",
    "print(f\"\\nLoaded images:\")\n",
    "print(f\"Source shape: {source.shape}\")\n",
    "print(f\"Target shape: {target.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess images\n",
    "print(\"Preprocessing images...\")\n",
    "# source_prep,target_prep=source,target\n",
    "source_prep, target_prep,padding_params =pad_images(source, target)\n",
    "\n",
    "# Extract tissue masks\n",
    "print(\"Extracting tissue masks...\")\n",
    "source_mask, target_mask = extract_tissue_masks(source_prep, target_prep, artefacts=False)\n",
    "\n",
    "print(\"✅ Preprocessing completed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Visualize Image and Tissue Masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display original images side by side\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 12))\n",
    "\n",
    "axes[0, 0].imshow(source_prep)\n",
    "axes[0, 0].set_title('Source Image (Moving)')\n",
    "axes[0, 0].axis('off')\n",
    "\n",
    "axes[0, 1].imshow(target_prep)\n",
    "axes[0, 1].set_title('Target Image (Fixed)')\n",
    "axes[0, 1].axis('off')\n",
    "\n",
    "axes[1, 0].imshow(source_mask, cmap='gray')\n",
    "axes[1, 0].set_title('Source Tissue Mask')\n",
    "axes[1, 0].axis('off')\n",
    "\n",
    "axes[1, 1].imshow(target_mask, cmap='gray')\n",
    "axes[1, 1].set_title('Target Tissue Mask')\n",
    "axes[1, 1].axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Coarse Registration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform rigid registration\n",
    "print(\"Performing rigid registration...\")\n",
    "moving_img_transformed, final_transform = perform_rigid_registration(\n",
    "    source_prep, target_prep, source_mask, target_mask\n",
    ")\n",
    "visualize_overlays(target_prep, source_prep, moving_img_transformed)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "u_x, u_y = util.rigid_dot(source_prep,np.linalg.inv(final_transform))\n",
    "deformation_field = np.stack(( u_x, u_y), axis=-1)\n",
    "sitk_image = sitk.GetImageFromArray(deformation_field)\n",
    "\n",
    "\n",
    "def tensor_to_rgb_numpy(tensor):\n",
    "    # (1, 1, H, W) -> (3, H, W) -> (H, W, 3)\n",
    "    tensor_rgb = tensor.squeeze().repeat(3, 1, 1)\n",
    "    return tensor_rgb.permute(1, 2, 0).detach().cpu().numpy()\n",
    "\n",
    "# coarse nonrigid\n",
    "\n",
    "displacement_field,warped_source= elastic_image_registration(\n",
    "   moving_img_transformed,\n",
    "   target_prep,\n",
    "     compute_device='cuda'  \n",
    ")\n",
    "print(\"non rigid displacement field\",displacement_field.shape)\n",
    "\n",
    "visualize_overlays(target_prep, source_prep,  tensor_to_rgb_numpy(warped_source))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "disp_field_np=util.tc_df_to_np_df(displacement_field)\n",
    "w_x,w_y=util.compose_vector_fields(u_x, u_y, disp_field_np[0], disp_field_np[1])\n",
    "deformation_field = np.stack(( w_x, w_y), axis=-1)\n",
    "sitk_image = sitk.GetImageFromArray(deformation_field)\n",
    "sitk.WriteImage(sitk_image, './533.mha')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. TIAViz Registration Visualization "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash \n",
    "export BOKEH_ALLOW_WS_ORIGIN=localhost:5007\n",
    "tiatoolbox visualize --slides \"path-to-slides\" --overlays \"path-to-overlays\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Patch Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale transformation for high resolution analysis\n",
    "transform_40x = scale_transformation_matrix(\n",
    "    final_transform, PREPROCESSING_RESOLUTION, REGISTRATION_RESOLUTION\n",
    ")\n",
    "\n",
    "# Extract patches from target WSI\n",
    "print(\"\\nExtracting patches...\")\n",
    "fixed_patch_extractor = extract_patches_from_wsi(\n",
    "    target_wsi, target_mask, PATCH_SIZE, PATCH_STRIDE\n",
    ")\n",
    "\n",
    "print(f\"Total patches extracted: {len(fixed_patch_extractor)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Coarse  Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select a patch for visualization\n",
    "patch_idx = 70  # You can change this index\n",
    "loc = fixed_patch_extractor.coordinate_list[patch_idx]\n",
    "location = (loc[0], loc[1])\n",
    "\n",
    "print(f\"Visualizing patch {patch_idx} at location {location}\")\n",
    "\n",
    "# Extract regions for comparison\n",
    "fixed_tile = target_wsi.read_rect(location, VISUALIZATION_SIZE, resolution=40, units=\"power\")\n",
    "moving_tile = source_wsi.read_rect(location, VISUALIZATION_SIZE, resolution=40, units=\"power\")\n",
    "\n",
    "# Create transformer and extract transformed tile\n",
    "tfm = AffineWSITransformer(source_wsi, transform_40x)\n",
    "transformed_tile = tfm.read_rect(location=location, size=VISUALIZATION_SIZE, resolution=0, units=\"level\")\n",
    "\n",
    "# Visualize patches\n",
    "visualize_patches(fixed_tile, moving_tile, transformed_tile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_overlays(fixed_tile, moving_tile, transformed_tile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Interactive Nuclei Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "FIXED_NUCLEI_CSV=\"/home/u5552013/Nextcloud/HYRECO/Data/nuclei_points/he_533_nuclei.csv\"\n",
    "MOVING_NUCLEI_CSV=\"/home/u5552013/Nextcloud/HYRECO/Data/nuclei_points/ki67_533_nuclei.csv\"\n",
    "\n",
    "# Load nuclei coordinates\n",
    "moving_df = load_nuclei_coordinates(MOVING_NUCLEI_CSV)\n",
    "fixed_df = load_nuclei_coordinates(FIXED_NUCLEI_CSV)\n",
    "\n",
    "print(f\"Loaded nuclei data:\")\n",
    "print(f\"- Fixed nuclei: {len(fixed_df)}\")\n",
    "print(f\"- Moving nuclei: {len(moving_df)}\")\n",
    "\n",
    "# Create basic nuclei overlay plot\n",
    "print(\"\\nCreating interactive nuclei overlay plot...\")\n",
    "plot1 = create_nuclei_overlay_plot(moving_df, fixed_df, \n",
    "                                  \"Original Nuclei Coordinates (Before Registration)\")\n",
    "show_plot(plot1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "deformation_field, moving_updated, fixed_points, moving_points= compute_deformation_and_apply(    source_prep,\n",
    "    final_transform,\n",
    "    displacement_field,\n",
    "    moving_df,\n",
    "    fixed_df,\n",
    "    padding_params,\n",
    "    util,\n",
    "    pad_landmarks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_cluster_alignment(\n",
    "    fixed_points,\n",
    "    moving_points,\n",
    "    moving_updated,\n",
    "    # fixed_df=None,\n",
    "    # moving_df=None,\n",
    "    figsize=(10, 10),\n",
    "    title='Cluster Centers: Fixed, Original Moving, and Transformed',\n",
    "    save_path=None\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Shape-Aware Point Set Registration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.spatial import KDTree\n",
    "\n",
    "\n",
    "class ShapeAwarePointSetRegistration:\n",
    "    def __init__(self, fixed_points, moving_points,\n",
    "                 shape_attribute=None, shape_weight=0.0,\n",
    "                 max_iterations=50, tolerance=1e-6,\n",
    "                 allow_scaling=False):\n",
    "\n",
    "        # --- Convert inputs to numpy arrays ---\n",
    "        if isinstance(fixed_points, pd.DataFrame):\n",
    "            self.fixed = fixed_points[['x', 'y']].values.astype(np.float64)\n",
    "            self.fixed_shape = (fixed_points[shape_attribute].values.astype(np.float64) \n",
    "                               if shape_attribute and shape_attribute in fixed_points else None)\n",
    "        else:\n",
    "            self.fixed = np.asarray(fixed_points, dtype=np.float64)\n",
    "            self.fixed_shape = None\n",
    "\n",
    "        if isinstance(moving_points, pd.DataFrame):\n",
    "            self.moving = moving_points[['x', 'y']].values.astype(np.float64)\n",
    "            self.moving_shape = (moving_points[shape_attribute].values.astype(np.float64)\n",
    "                                if shape_attribute and shape_attribute in moving_points else None)\n",
    "        else:\n",
    "            self.moving = np.asarray(moving_points, dtype=np.float64)\n",
    "            self.moving_shape = None\n",
    "\n",
    "        if self.fixed.shape[1] != 2 or self.moving.shape[1] != 2:\n",
    "            raise ValueError(\"Both fixed_points and moving_points must have exactly 2 columns (x, y).\")\n",
    "\n",
    "        self.shape_weight = np.clip(shape_weight, 0.0, 1.0)\n",
    "        self.max_iterations = max_iterations\n",
    "        self.tolerance = tolerance\n",
    "        self.allow_scaling = allow_scaling\n",
    "\n",
    "        # Normalize shape attributes for better weighting\n",
    "        if self.fixed_shape is not None and self.moving_shape is not None:\n",
    "            shape_std = np.std(self.fixed_shape)\n",
    "            if shape_std > 1e-9:\n",
    "                self.shape_scale = shape_std\n",
    "            else:\n",
    "                self.shape_scale = 1.0\n",
    "        else:\n",
    "            self.shape_scale = 1.0\n",
    "\n",
    "        self.rotation = 0.0\n",
    "        self.scale = 1.0\n",
    "        self.translation = np.zeros(2)\n",
    "\n",
    "    def _apply_transform(self, points, R, t, s):\n",
    "        \"\"\"Apply similarity transform with vectorized operations.\"\"\"\n",
    "        return s * np.dot(points, R.T) + t\n",
    "\n",
    "    def _estimate_rigid_transform(self, A, B, weights=None):\n",
    "        \"\"\"Estimate weighted similarity transform (rotation, translation, scale).\"\"\"\n",
    "        if weights is None:\n",
    "            weights = np.ones(len(A))\n",
    "        \n",
    "        weights = weights / np.sum(weights)  # normalize weights\n",
    "        \n",
    "        # Weighted centroids\n",
    "        centroid_A = np.sum(A * weights[:, np.newaxis], axis=0)\n",
    "        centroid_B = np.sum(B * weights[:, np.newaxis], axis=0)\n",
    "        \n",
    "        AA = A - centroid_A\n",
    "        BB = B - centroid_B\n",
    "        \n",
    "        # Weighted covariance\n",
    "        H = np.dot(AA.T, BB * weights[:, np.newaxis])\n",
    "        \n",
    "        U, _, Vt = np.linalg.svd(H)\n",
    "        R = np.dot(Vt.T, U.T)\n",
    "        \n",
    "        # Ensure proper rotation (det = 1)\n",
    "        if np.linalg.det(R) < 0:\n",
    "            Vt[-1, :] *= -1\n",
    "            R = np.dot(Vt.T, U.T)\n",
    "\n",
    "        if self.allow_scaling:\n",
    "            num = np.sum(weights[:, np.newaxis] * BB * np.dot(AA, R))\n",
    "            den = np.sum(weights[:, np.newaxis] * AA * AA)\n",
    "            s = num / (den + 1e-9)\n",
    "            s = max(0.1, min(s, 10.0))  # clamp scale to reasonable range\n",
    "        else:\n",
    "            s = 1.0\n",
    "\n",
    "        t = centroid_B - s * np.dot(R, centroid_A)\n",
    "        return R, t, s\n",
    "\n",
    "    def register(self):\n",
    "        \"\"\"Perform iterative closest point registration with shape awareness.\"\"\"\n",
    "        fixed_xy = self.fixed\n",
    "        moving_xy = self.moving\n",
    "        n_moving = len(moving_xy)\n",
    "\n",
    "        R = np.eye(2)\n",
    "        t = np.zeros(2)\n",
    "        s = 1.0\n",
    "        prev_error = np.inf\n",
    "\n",
    "        # Pre-compute spatial distance scale for normalization\n",
    "        spatial_std = np.std(fixed_xy, axis=0).mean()\n",
    "        if spatial_std < 1e-9:\n",
    "            spatial_std = 1.0\n",
    "\n",
    "        for it in range(self.max_iterations):\n",
    "            transformed = self._apply_transform(moving_xy, R, t, s)\n",
    "\n",
    "            # --- Step 1: Find spatial nearest neighbors ---\n",
    "            kdtree = KDTree(fixed_xy)\n",
    "            spatial_dists, spatial_idx = kdtree.query(transformed, k=1)\n",
    "\n",
    "            # --- Step 2: Refine correspondences with shape information ---\n",
    "            if self.shape_weight > 0 and self.fixed_shape is not None and self.moving_shape is not None:\n",
    "                # Normalize spatial distances\n",
    "                norm_spatial_dists = spatial_dists / spatial_std\n",
    "                \n",
    "                # Compute shape distances\n",
    "                shape_dists = np.abs(self.fixed_shape[spatial_idx] - self.moving_shape) / self.shape_scale\n",
    "                \n",
    "                # Combined distance metric\n",
    "                combined_dists = (1 - self.shape_weight) * norm_spatial_dists + self.shape_weight * shape_dists\n",
    "                \n",
    "                # For better matching, consider k-nearest neighbors and pick best combined match\n",
    "                k_neighbors = min(5, len(fixed_xy))\n",
    "                nn_dists, nn_idx = kdtree.query(transformed, k=k_neighbors)\n",
    "                \n",
    "                best_idx = np.zeros(n_moving, dtype=int)\n",
    "                for i in range(n_moving):\n",
    "                    candidates = nn_idx[i]\n",
    "                    spatial_d = nn_dists[i] / spatial_std\n",
    "                    shape_d = np.abs(self.fixed_shape[candidates] - self.moving_shape[i]) / self.shape_scale\n",
    "                    combined = (1 - self.shape_weight) * spatial_d + self.shape_weight * shape_d\n",
    "                    best_idx[i] = candidates[np.argmin(combined)]\n",
    "                \n",
    "                idx = best_idx\n",
    "                matched_fixed = fixed_xy[idx]\n",
    "                \n",
    "                # Weight matches by inverse distance for robustness\n",
    "                weights = 1.0 / (combined_dists + 1e-6)\n",
    "            else:\n",
    "                idx = spatial_idx\n",
    "                matched_fixed = fixed_xy[idx]\n",
    "                weights = 1.0 / (spatial_dists + 1e-6)\n",
    "\n",
    "            # --- Step 3: Estimate transform with weighted least squares ---\n",
    "            R_new, t_new, s_new = self._estimate_rigid_transform(moving_xy, matched_fixed, weights)\n",
    "\n",
    "            # --- Step 4: Update transform ---\n",
    "            R = R_new\n",
    "            t = t_new\n",
    "            s = s_new\n",
    "\n",
    "            # --- Step 5: Compute alignment error ---\n",
    "            transformed_new = self._apply_transform(moving_xy, R, t, s)\n",
    "            errors = np.linalg.norm(matched_fixed - transformed_new, axis=1)\n",
    "            error = np.mean(errors)\n",
    "            \n",
    "            # Check convergence\n",
    "            if it > 0 and np.abs(prev_error - error) < self.tolerance * max(prev_error, 1.0):\n",
    "                break\n",
    "            prev_error = error\n",
    "\n",
    "        # Final transformation\n",
    "        transformed_final = self._apply_transform(moving_xy, R, t, s)\n",
    "\n",
    "        self.rotation = np.arctan2(R[1, 0], R[0, 0])\n",
    "        self.translation = t\n",
    "        self.scale = s\n",
    "        self.final_error = prev_error\n",
    "        self.num_iterations = it + 1\n",
    "\n",
    "        self.registered_points = pd.DataFrame({\n",
    "            'x': moving_xy[:, 0],\n",
    "            'y': moving_xy[:, 1],\n",
    "            'registered_x': transformed_final[:, 0],\n",
    "            'registered_y': transformed_final[:, 1]\n",
    "        })\n",
    "\n",
    "        return self.registered_points\n",
    "\n",
    "    def get_transformation_matrix(self):\n",
    "        \"\"\"Return 3x3 homogeneous transformation matrix.\"\"\"\n",
    "        theta = self.rotation\n",
    "        cos_t, sin_t = np.cos(theta), np.sin(theta)\n",
    "        tx, ty = self.translation\n",
    "        s = self.scale\n",
    "        return np.array([\n",
    "            [s * cos_t, -s * sin_t, tx],\n",
    "            [s * sin_t,  s * cos_t, ty],\n",
    "            [0,          0,         1]\n",
    "        ])\n",
    "\n",
    "\n",
    "def perform_shape_aware_registration(fixed_df, moving_df,\n",
    "                                     shape_attribute=None,\n",
    "                                     shape_weight=0.0,\n",
    "                                     max_iterations=50,\n",
    "                                     tolerance=1e-6,\n",
    "                                     allow_scaling=False):\n",
    "    \"\"\"\n",
    "    Convenience function for shape-aware point set registration.\n",
    "    \n",
    "    Returns:\n",
    "        registrator: The registration object with transformation parameters\n",
    "        transform_matrix: 3x3 homogeneous transformation matrix\n",
    "        coords: Nx2 array of registered coordinates\n",
    "    \"\"\"\n",
    "    registrator = ShapeAwarePointSetRegistration(\n",
    "        fixed_df, moving_df,\n",
    "        shape_attribute=shape_attribute,\n",
    "        shape_weight=shape_weight,\n",
    "        max_iterations=max_iterations,\n",
    "        tolerance=tolerance,\n",
    "        allow_scaling=allow_scaling\n",
    "    )\n",
    "    registered_points = registrator.register()\n",
    "    transform_matrix = registrator.get_transformation_matrix()\n",
    "    coords = registered_points[['registered_x', 'registered_y']].values\n",
    "    return registrator, transform_matrix, coords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform shape-aware registration \n",
    "print(\"Performing Shape-Aware Point Set Registration...\")\n",
    "\n",
    "#  No of subsampling points can be adjusted\n",
    "fixed_subsample =util.skip_subsample(fixed_df, n_samples=1000)\n",
    "moving_subsample = util.skip_subsample(moving_df, n_samples=1000)\n",
    "\n",
    "#  fine pointset registration\n",
    "shape_registrator,shape_transform, shape_transformed_coords   = perform_shape_aware_registration(\n",
    "    fixed_points,moving_updated,\n",
    "    shape_attribute=None,\n",
    "    shape_weight=0.3,  # 30% weight for shape, 70% for spatial distance\n",
    "    max_iterations=100,\n",
    "    tolerance=1e-11\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # #  icp registration\n",
    "# transformation, transformed_points=perform_icp_registration( moving_updated,fixed_points,threshold=5000000)\n",
    "# T_sub = np.delete(np.delete(transformation, 2, axis=0), 2, axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fixed_subsample =util.skip_subsample(fixed_points, n_samples=1000)\n",
    "moving_subsample = util.skip_subsample(shape_transformed_coords, n_samples=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X = fixed_subsample[['global_x', 'global_y']].values\n",
    "# Y = moving_subsample[['global_x','global_y']].values\n",
    "X=fixed_subsample\n",
    "Y=moving_subsample\n",
    "print('Non-rigid CPD:')\n",
    "cpd_nonrigid = CPD(method='nonrigid')\n",
    "nonrigid_transformed_coords , P = cpd_nonrigid(X, Y, w=0, max_iterations=50)\n",
    "# print(f'Non-rigid alignment: {np.argmax(P, axis=1)}\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# from scipy.interpolate import griddata\n",
    "\n",
    "# # Existing grid\n",
    "# H, W = u_x.shape\n",
    "# grid_y, grid_x = np.mgrid[0:H, 0:W]\n",
    "\n",
    "# # Sparse CPD displacement\n",
    "# cpd_points = X  # (N,2)\n",
    "# dx = disp_field_np[:,0]\n",
    "# dy = disp_field_np[:,1]\n",
    "\n",
    "# # Interpolate to full grid\n",
    "# full_dx = griddata(cpd_points, dx, (grid_x, grid_y), method='cubic', fill_value=0)\n",
    "# full_dy = griddata(cpd_points, dy, (grid_x, grid_y), method='cubic', fill_value=0)\n",
    "\n",
    "# # Now compose\n",
    "# w_x, w_y = util.compose_vector_fields(u_x, u_y, full_dx, full_dy)\n",
    "# deformation_field = np.stack((w_x, w_y), axis=-1)\n",
    "\n",
    "# # Save\n",
    "# sitk_image = sitk.GetImageFromArray(deformation_field)\n",
    "# sitk.WriteImage(sitk_image, './cpd_deformation_field.mha')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from pycpd import DeformableRegistration as CPD\n",
    "\n",
    "# Assume X (fixed) and Y (moving) are numpy arrays of shape (N, 2) or (N, 3)\n",
    "# Y = moving_subsample\n",
    "X=fixed_subsample\n",
    "Y=moving_subsample\n",
    "print('Non-rigid CPD:')\n",
    "cpd_nonrigid = CPD(X=X, Y=Y, w=0.05,beta=1.5, lambda_=2.0, max_iterations=200)\n",
    "nonrigid_transformed_coords, P = cpd_nonrigid.register()\n",
    "\n",
    "# --- Visualization ---\n",
    "fig = plt.figure(figsize=(12, 5))\n",
    "\n",
    "# Before registration\n",
    "ax1 = fig.add_subplot(1, 2, 1)\n",
    "ax1.scatter(X[:, 0], X[:, 1], c='red', label='Fixed (X)', alpha=0.7)\n",
    "ax1.scatter(Y[:, 0], Y[:, 1], c='blue', label='Moving (Y)', alpha=0.7)\n",
    "ax1.set_title('Before Non-Rigid Registration')\n",
    "ax1.legend()\n",
    "ax1.axis('equal')\n",
    "\n",
    "# After registration\n",
    "ax2 = fig.add_subplot(1, 2, 2)\n",
    "ax2.scatter(X[:, 0], X[:, 1], c='red', label='Fixed (X)', alpha=0.7)\n",
    "ax2.scatter(nonrigid_transformed_coords[:, 0], nonrigid_transformed_coords[:, 1], \n",
    "            c='green', label='Transformed (Y)', alpha=0.7)\n",
    "ax2.set_title('After Non-Rigid Registration')\n",
    "ax2.legend()\n",
    "ax2.axis('equal')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fine_deform=util.create_deformation_field(shape_transform, source_prep, u_x, u_y, util, output_path='./533_finerigid.mha')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tiatoolbox.wsicore.wsireader import TransformedWSIReader\n",
    "from pathlib import Path\n",
    "# Select a patch for visualization\n",
    "patch_idx = 70  # You can change this index\n",
    "loc = fixed_patch_extractor.coordinate_list[patch_idx]\n",
    "location = (loc[0], loc[1])\n",
    "\n",
    "print(f\"Visualizing patch {patch_idx} at location {location}\")\n",
    "\n",
    "# Extract regions for comparison\n",
    "fixed_tile = target_wsi.read_rect(location, size=(5000, 5000), resolution=40, units=\"power\")\n",
    "moving_tile = source_wsi.read_rect(location, size=(5000, 5000), resolution=40, units=\"power\")\n",
    "\n",
    "transformed_wsi = TransformedWSIReader(input_img=SOURCE_WSI_PATH, target_img=TARGET_WSI_PATH,  transform=Path('./533_finerigid.mha'))\n",
    "transformed_tile = transformed_wsi.read_rect( location,   size= (5000, 5000),  resolution=40,    units=\"power\" )\n",
    "\n",
    "# Visualize patches\n",
    "visualize_patches(fixed_tile, moving_tile, transformed_tile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_overlays(fixed_tile, moving_tile, transformed_tile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.ndimage import map_coordinates\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Create displacement field for spatial transformation analysis\n",
    "print(\"Creating displacement field...\")\n",
    "\n",
    "# Scale down coordinates for field generation\n",
    "scale_factor = 64\n",
    "source_points_scaled = moving_subsample  / scale_factor\n",
    "target_points_scaled =nonrigid_transformed_coords / scale_factor\n",
    "\n",
    "\n",
    "\n",
    "from scipy.interpolate import griddata\n",
    "\n",
    "# Existing grid\n",
    "H, W = u_x.shape\n",
    "grid_y, grid_x = np.mgrid[0:H, 0:W]\n",
    "displacement_field = create_displacement_field(\n",
    "    source_points_scaled, target_points_scaled,\n",
    "    target_prep.shape,\n",
    "    method=RegistrationParams.INTERPOLATION_METHOD,\n",
    "    sigma=RegistrationParams.DISPLACEMENT_SIGMA,\n",
    "    max_displacement=RegistrationParams.MAX_DISPLACEMENT\n",
    ")\n",
    "fr_x,fr_y=util.compose_vector_fields( w_x, w_y, displacement_field[..., 0],displacement_field[..., 1])\n",
    "\n",
    "deformation_field = np.stack(( w_x, w_y), axis=-1)\n",
    "sitk_image = sitk.GetImageFromArray(deformation_field)\n",
    "sitk.WriteImage(sitk_image, './533_nonrigid.mha')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tiatoolbox.wsicore.wsireader import TransformedWSIReader\n",
    "from pathlib import Path\n",
    "# Select a patch for visualization\n",
    "patch_idx = 70  # You can change this index\n",
    "loc = fixed_patch_extractor.coordinate_list[patch_idx]\n",
    "location = (loc[0], loc[1])\n",
    "\n",
    "print(f\"Visualizing patch {patch_idx} at location {location}\")\n",
    "\n",
    "# Extract regions for comparison\n",
    "fixed_tile = target_wsi.read_rect(location, size=(5000, 5000), resolution=40, units=\"power\")\n",
    "moving_tile = source_wsi.read_rect(location, size=(5000, 5000), resolution=40, units=\"power\")\n",
    "\n",
    "transformed_wsi = TransformedWSIReader(input_img=SOURCE_WSI_PATH, target_img=TARGET_WSI_PATH,  transform=Path('./533_nonrigid.mha'))\n",
    "transformed_tile = transformed_wsi.read_rect( location,   size= (5000, 5000),  resolution=40,    units=\"power\" )\n",
    "\n",
    "# Visualize patches\n",
    "visualize_patches(fixed_tile, moving_tile, transformed_tile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_overlays(fixed_tile,moving_tile, transformed_tile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tiatoolbox.wsicore.wsireader import TransformedWSIReader\n",
    "from pathlib import Path\n",
    "# Select a patch for visualization\n",
    "patch_idx = 70  # You can change this index\n",
    "loc = fixed_patch_extractor.coordinate_list[patch_idx]\n",
    "location = (loc[0], loc[1])\n",
    "\n",
    "print(f\"Visualizing patch {patch_idx} at location {location}\")\n",
    "\n",
    "# Extract regions for comparison\n",
    "fixed_tile = target_wsi.read_rect(location, size=(5000, 5000), resolution=40, units=\"power\")\n",
    "moving_tile = source_wsi.read_rect(location, size=(5000, 5000), resolution=40, units=\"power\")\n",
    "\n",
    "transformed_wsi = TransformedWSIReader(input_img=SOURCE_WSI_PATH, target_img=TARGET_WSI_PATH,  transform=Path('./533_nonrigid.mha'))\n",
    "transformed_tile = transformed_wsi.read_rect( location,   size= (5000, 5000),  resolution=40,    units=\"power\" )\n",
    "\n",
    "# Visualize patches\n",
    "visualize_patches(fixed_tile, moving_tile, transformed_tile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_overlays(fixed_tile,moving_tile, transformed_tile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. TIAViz Registration Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash \n",
    "export BOKEH_ALLOW_WS_ORIGIN=localhost:5007\n",
    "\n",
    "tiatoolbox visualize --slides \"path-to-slides\" --overlays \"path-to-overlays\"\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tiatoolbox-reg-vis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
